{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a30516b7-059f-42b2-85a6-256e3b54d93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aajit\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.3285 - loss: 1.2245 - val_accuracy: 0.3177 - val_loss: 1.2013\n",
      "Epoch 2/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3243 - loss: 1.1925 - val_accuracy: 0.3174 - val_loss: 1.2000\n",
      "Epoch 3/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3285 - loss: 1.1924 - val_accuracy: 0.3172 - val_loss: 1.2007\n",
      "Epoch 4/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3306 - loss: 1.1916 - val_accuracy: 0.3172 - val_loss: 1.2008\n",
      "Epoch 5/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3292 - loss: 1.1922 - val_accuracy: 0.3177 - val_loss: 1.2019\n",
      "Epoch 6/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3309 - loss: 1.1932 - val_accuracy: 0.3286 - val_loss: 1.2003\n",
      "Epoch 7/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3240 - loss: 1.1902 - val_accuracy: 0.3172 - val_loss: 1.2007\n",
      "Epoch 8/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3291 - loss: 1.1903 - val_accuracy: 0.3286 - val_loss: 1.2000\n",
      "Epoch 9/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3264 - loss: 1.1953 - val_accuracy: 0.3172 - val_loss: 1.2003\n",
      "Epoch 10/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3230 - loss: 1.1914 - val_accuracy: 0.3297 - val_loss: 1.2003\n",
      "Epoch 11/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3236 - loss: 1.1933 - val_accuracy: 0.3172 - val_loss: 1.2009\n",
      "Epoch 12/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3288 - loss: 1.1927 - val_accuracy: 0.3286 - val_loss: 1.2001\n",
      "Epoch 13/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3270 - loss: 1.1912 - val_accuracy: 0.3172 - val_loss: 1.2000\n",
      "Epoch 14/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3282 - loss: 1.1874 - val_accuracy: 0.3250 - val_loss: 1.2009\n",
      "Epoch 15/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3225 - loss: 1.1905 - val_accuracy: 0.3172 - val_loss: 1.2004\n",
      "Epoch 16/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3284 - loss: 1.1886 - val_accuracy: 0.3286 - val_loss: 1.2005\n",
      "Epoch 17/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3263 - loss: 1.1901 - val_accuracy: 0.3172 - val_loss: 1.2009\n",
      "Epoch 18/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3255 - loss: 1.1889 - val_accuracy: 0.3172 - val_loss: 1.2000\n",
      "Epoch 19/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3259 - loss: 1.1887 - val_accuracy: 0.3315 - val_loss: 1.1997\n",
      "Epoch 20/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3267 - loss: 1.1898 - val_accuracy: 0.3284 - val_loss: 1.1999\n",
      "Epoch 21/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3276 - loss: 1.1894 - val_accuracy: 0.3172 - val_loss: 1.2008\n",
      "Epoch 22/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3239 - loss: 1.1898 - val_accuracy: 0.3172 - val_loss: 1.2001\n",
      "Epoch 23/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3328 - loss: 1.1886 - val_accuracy: 0.3245 - val_loss: 1.2000\n",
      "Epoch 24/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3318 - loss: 1.1916 - val_accuracy: 0.3172 - val_loss: 1.2010\n",
      "Epoch 25/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3283 - loss: 1.1936 - val_accuracy: 0.3250 - val_loss: 1.2007\n",
      "Epoch 26/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3252 - loss: 1.1945 - val_accuracy: 0.3172 - val_loss: 1.2011\n",
      "Epoch 27/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3249 - loss: 1.1893 - val_accuracy: 0.3172 - val_loss: 1.2001\n",
      "Epoch 28/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3257 - loss: 1.1905 - val_accuracy: 0.3312 - val_loss: 1.1999\n",
      "Epoch 29/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3287 - loss: 1.1884 - val_accuracy: 0.3245 - val_loss: 1.1997\n",
      "Epoch 30/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3285 - loss: 1.1886 - val_accuracy: 0.3172 - val_loss: 1.2008\n",
      "Epoch 31/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3282 - loss: 1.1908 - val_accuracy: 0.3252 - val_loss: 1.2000\n",
      "Epoch 32/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3183 - loss: 1.1916 - val_accuracy: 0.3172 - val_loss: 1.2013\n",
      "Epoch 33/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3241 - loss: 1.1929 - val_accuracy: 0.3172 - val_loss: 1.2006\n",
      "Epoch 34/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3305 - loss: 1.1923 - val_accuracy: 0.3279 - val_loss: 1.2002\n",
      "Epoch 35/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3236 - loss: 1.1902 - val_accuracy: 0.3293 - val_loss: 1.2005\n",
      "Epoch 36/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3283 - loss: 1.1933 - val_accuracy: 0.3248 - val_loss: 1.2008\n",
      "Epoch 37/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3292 - loss: 1.1928 - val_accuracy: 0.3237 - val_loss: 1.2000\n",
      "Epoch 38/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3253 - loss: 1.1911 - val_accuracy: 0.3180 - val_loss: 1.2000\n",
      "Epoch 39/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3249 - loss: 1.1896 - val_accuracy: 0.3177 - val_loss: 1.2000\n",
      "Epoch 40/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3232 - loss: 1.1898 - val_accuracy: 0.3177 - val_loss: 1.2001\n",
      "Epoch 41/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3291 - loss: 1.1904 - val_accuracy: 0.3173 - val_loss: 1.2005\n",
      "Epoch 42/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3245 - loss: 1.1906 - val_accuracy: 0.3200 - val_loss: 1.2001\n",
      "Epoch 43/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3300 - loss: 1.1923 - val_accuracy: 0.3288 - val_loss: 1.2000\n",
      "Epoch 44/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3275 - loss: 1.1895 - val_accuracy: 0.3237 - val_loss: 1.2001\n",
      "Epoch 45/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3302 - loss: 1.1873 - val_accuracy: 0.3172 - val_loss: 1.2006\n",
      "Epoch 46/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3262 - loss: 1.1916 - val_accuracy: 0.3265 - val_loss: 1.2000\n",
      "Epoch 47/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3263 - loss: 1.1888 - val_accuracy: 0.3254 - val_loss: 1.1995\n",
      "Epoch 48/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3245 - loss: 1.1917 - val_accuracy: 0.3319 - val_loss: 1.1998\n",
      "Epoch 49/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3282 - loss: 1.1897 - val_accuracy: 0.3264 - val_loss: 1.1997\n",
      "Epoch 50/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3322 - loss: 1.1934 - val_accuracy: 0.3175 - val_loss: 1.2022\n",
      "Epoch 51/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3309 - loss: 1.1908 - val_accuracy: 0.3225 - val_loss: 1.1998\n",
      "Epoch 52/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3277 - loss: 1.1902 - val_accuracy: 0.3174 - val_loss: 1.2004\n",
      "Epoch 53/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3348 - loss: 1.1912 - val_accuracy: 0.3273 - val_loss: 1.1998\n",
      "Epoch 54/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3312 - loss: 1.1891 - val_accuracy: 0.3263 - val_loss: 1.1999\n",
      "Epoch 55/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3287 - loss: 1.1894 - val_accuracy: 0.3277 - val_loss: 1.1998\n",
      "Epoch 56/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3260 - loss: 1.1927 - val_accuracy: 0.3172 - val_loss: 1.2006\n",
      "Epoch 57/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3315 - loss: 1.1883 - val_accuracy: 0.3253 - val_loss: 1.2001\n",
      "Epoch 58/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3297 - loss: 1.1927 - val_accuracy: 0.3263 - val_loss: 1.2000\n",
      "Epoch 59/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3274 - loss: 1.1871 - val_accuracy: 0.3222 - val_loss: 1.1999\n",
      "Epoch 60/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3262 - loss: 1.1894 - val_accuracy: 0.3187 - val_loss: 1.2002\n",
      "Epoch 61/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3316 - loss: 1.1904 - val_accuracy: 0.3209 - val_loss: 1.2001\n",
      "Epoch 62/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3268 - loss: 1.1921 - val_accuracy: 0.3205 - val_loss: 1.2001\n",
      "Epoch 63/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3299 - loss: 1.1911 - val_accuracy: 0.3175 - val_loss: 1.2005\n",
      "Epoch 64/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3274 - loss: 1.1945 - val_accuracy: 0.3186 - val_loss: 1.2001\n",
      "Epoch 65/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3280 - loss: 1.1931 - val_accuracy: 0.3175 - val_loss: 1.2004\n",
      "Epoch 66/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3232 - loss: 1.1878 - val_accuracy: 0.3169 - val_loss: 1.1999\n",
      "Epoch 67/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3294 - loss: 1.1899 - val_accuracy: 0.3175 - val_loss: 1.2003\n",
      "Epoch 68/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3314 - loss: 1.1875 - val_accuracy: 0.3199 - val_loss: 1.2000\n",
      "Epoch 69/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3327 - loss: 1.1878 - val_accuracy: 0.3295 - val_loss: 1.1999\n",
      "Epoch 70/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3278 - loss: 1.1886 - val_accuracy: 0.3175 - val_loss: 1.2009\n",
      "Epoch 71/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3299 - loss: 1.1899 - val_accuracy: 0.3346 - val_loss: 1.2040\n",
      "Epoch 72/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3226 - loss: 1.1911 - val_accuracy: 0.3203 - val_loss: 1.2000\n",
      "Epoch 73/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3296 - loss: 1.1889 - val_accuracy: 0.3257 - val_loss: 1.1997\n",
      "Epoch 74/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3256 - loss: 1.1902 - val_accuracy: 0.3192 - val_loss: 1.2001\n",
      "Epoch 75/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3257 - loss: 1.1893 - val_accuracy: 0.3251 - val_loss: 1.1998\n",
      "Epoch 76/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3287 - loss: 1.1923 - val_accuracy: 0.3270 - val_loss: 1.2001\n",
      "Epoch 77/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3274 - loss: 1.1911 - val_accuracy: 0.3204 - val_loss: 1.2001\n",
      "Epoch 78/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3299 - loss: 1.1919 - val_accuracy: 0.3211 - val_loss: 1.2000\n",
      "Epoch 79/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3243 - loss: 1.1904 - val_accuracy: 0.3209 - val_loss: 1.2000\n",
      "Epoch 80/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3309 - loss: 1.1911 - val_accuracy: 0.3269 - val_loss: 1.2000\n",
      "Epoch 81/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3290 - loss: 1.1922 - val_accuracy: 0.3288 - val_loss: 1.1999\n",
      "Epoch 82/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3280 - loss: 1.1879 - val_accuracy: 0.3272 - val_loss: 1.1997\n",
      "Epoch 83/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3326 - loss: 1.1937 - val_accuracy: 0.3244 - val_loss: 1.2006\n",
      "Epoch 84/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3218 - loss: 1.1940 - val_accuracy: 0.3228 - val_loss: 1.2007\n",
      "Epoch 85/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3287 - loss: 1.1905 - val_accuracy: 0.3209 - val_loss: 1.2001\n",
      "Epoch 86/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3259 - loss: 1.1913 - val_accuracy: 0.3193 - val_loss: 1.2004\n",
      "Epoch 87/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3299 - loss: 1.1908 - val_accuracy: 0.3266 - val_loss: 1.1997\n",
      "Epoch 88/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3265 - loss: 1.1897 - val_accuracy: 0.3219 - val_loss: 1.2000\n",
      "Epoch 89/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3283 - loss: 1.1899 - val_accuracy: 0.3214 - val_loss: 1.2000\n",
      "Epoch 90/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3300 - loss: 1.1885 - val_accuracy: 0.3201 - val_loss: 1.2002\n",
      "Epoch 91/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3329 - loss: 1.1899 - val_accuracy: 0.3223 - val_loss: 1.2000\n",
      "Epoch 92/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3273 - loss: 1.1888 - val_accuracy: 0.3204 - val_loss: 1.2000\n",
      "Epoch 93/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3266 - loss: 1.1918 - val_accuracy: 0.3236 - val_loss: 1.2001\n",
      "Epoch 94/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3262 - loss: 1.1903 - val_accuracy: 0.3215 - val_loss: 1.2002\n",
      "Epoch 95/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3301 - loss: 1.1879 - val_accuracy: 0.3218 - val_loss: 1.1999\n",
      "Epoch 96/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3287 - loss: 1.1903 - val_accuracy: 0.3195 - val_loss: 1.2005\n",
      "Epoch 97/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3308 - loss: 1.1909 - val_accuracy: 0.3197 - val_loss: 1.2013\n",
      "Epoch 98/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3277 - loss: 1.1893 - val_accuracy: 0.3191 - val_loss: 1.2008\n",
      "Epoch 99/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3342 - loss: 1.1898 - val_accuracy: 0.3233 - val_loss: 1.2001\n",
      "Epoch 100/100\n",
      "\u001b[1m1355/1355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.3334 - loss: 1.1877 - val_accuracy: 0.3241 - val_loss: 1.1999\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3229 - loss: 1.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# Step 1: Load and Preprocess Dataset\n",
    "data = pd.read_csv('lightning_roulette_results_reversed.csv', header=None, names=['number'])\n",
    "\n",
    "# Convert numbers to integers and remove invalid data\n",
    "data['number'] = pd.to_numeric(data['number'], errors='coerce')\n",
    "data = data.dropna(subset=['number'])\n",
    "data['number'] = data['number'].astype(int)\n",
    "\n",
    "# Map numbers to dozens, colors, parity, and high/low ranges\n",
    "def get_dozen(number):\n",
    "    if 1 <= number <= 12:\n",
    "        return 0  # Dozen 1\n",
    "    elif 13 <= number <= 24:\n",
    "        return 1  # Dozen 2\n",
    "    elif 25 <= number <= 36:\n",
    "        return 2  # Dozen 3\n",
    "    else:\n",
    "        return 3  # Green (0)\n",
    "\n",
    "def get_color(number):\n",
    "    red_numbers = {1, 3, 5, 7, 9, 12, 14, 16, 18, 19, 21, 23, 25, 27, 30, 32, 34, 36}\n",
    "    if number == 0:\n",
    "        return \"Green\"\n",
    "    elif number in red_numbers:\n",
    "        return \"Red\"\n",
    "    else:\n",
    "        return \"Black\"\n",
    "\n",
    "def get_parity(number):\n",
    "    return \"Even\" if number % 2 == 0 else \"Odd\"\n",
    "\n",
    "def get_high_low(number):\n",
    "    return \"Low\" if 1 <= number <= 18 else \"High\"\n",
    "\n",
    "data['dozen'] = data['number'].apply(get_dozen)\n",
    "data['color'] = data['number'].apply(get_color)\n",
    "data['parity'] = data['number'].apply(get_parity)\n",
    "data['high_low'] = data['number'].apply(get_high_low)\n",
    "\n",
    "# Convert categorical columns to numerical values\n",
    "color_mapping = {\"Red\": 1, \"Black\": 0, \"Green\": 2}\n",
    "parity_mapping = {\"Even\": 1, \"Odd\": 0}\n",
    "high_low_mapping = {\"Low\": 1, \"High\": 0}\n",
    "\n",
    "data['color'] = data['color'].map(color_mapping)\n",
    "data['parity'] = data['parity'].map(parity_mapping)\n",
    "data['high_low'] = data['high_low'].map(high_low_mapping)\n",
    "\n",
    "# Step 2: Define the roulette wheel layout\n",
    "roulette_wheel = [\n",
    "    0, 32, 15, 19, 4, 21, 2, 25, 17, 34, 6, 27, 13, 36, 11, 30, 8, 23, 10, 5, 24, 16, 33, 1, 20, 14, 31, 9, 22, 18, 29, 7, 28, 12, 35, 3, 26\n",
    "]\n",
    "\n",
    "# Step 3: Create a dictionary for fast access to neighbors\n",
    "wheel_neighbors = {}\n",
    "for i, number in enumerate(roulette_wheel):\n",
    "    neighbors = [roulette_wheel[(i-1) % len(roulette_wheel)], roulette_wheel[(i+1) % len(roulette_wheel)]]\n",
    "    wheel_neighbors[number] = neighbors\n",
    "\n",
    "# Step 4: Define the sections based on the Voisins, Tiers, and Orphelins sets\n",
    "voisins = {22, 18, 29, 7, 28, 12, 35, 3, 26, 0, 32, 15, 19, 4, 21, 2, 25}\n",
    "tiers = {27, 13, 36, 11, 30, 8, 23, 10, 5, 24, 16, 33}\n",
    "orphelins = {17, 34, 6, 1, 20, 14, 31, 9}\n",
    "\n",
    "def get_section(number):\n",
    "    if number in voisins:\n",
    "        return \"Voisins\"\n",
    "    elif number in tiers:\n",
    "        return \"Tiers\"\n",
    "    elif number in orphelins:\n",
    "        return \"Orphelins\"\n",
    "    else:\n",
    "        return \"Green\"  # For 0, it's part of the \"Green\" section\n",
    "\n",
    "# Step 5: Apply new features to the dataframe\n",
    "data['wheel_neighbors_1'] = data['number'].apply(lambda x: wheel_neighbors[x][0])\n",
    "data['wheel_neighbors_2'] = data['number'].apply(lambda x: wheel_neighbors[x][1])\n",
    "data['section'] = data['number'].apply(get_section)\n",
    "\n",
    "# Step 6: Map the 'section' to numerical values\n",
    "section_mapping = {\"Voisins\": 0, \"Tiers\": 1, \"Orphelins\": 2, \"Green\": 3}\n",
    "data['section'] = data['section'].map(section_mapping)\n",
    "\n",
    "# Step 7: Add the 'column' feature (1, 2, or 3)\n",
    "def get_column(number):\n",
    "    if number == 0:\n",
    "        return 0  # For number 0, set column as 0\n",
    "    else:\n",
    "        return (number - 1) % 3 + 1\n",
    "\n",
    "data['column'] = data['number'].apply(get_column)\n",
    "\n",
    "# Step 8: Map the 'column' to numerical values (mapping already returns 1, 2, or 3, so no additional mapping needed)\n",
    "\n",
    "\n",
    "\n",
    "# Step 9: Create lag features (last 10 spins as input sequence)\n",
    "def create_lag_features(df, lag_count):\n",
    "    lagged_data = []\n",
    "    target = []\n",
    "    for i in range(len(df) - lag_count):\n",
    "        lagged_data.append(df[['number', 'color', 'parity', 'high_low', 'wheel_neighbors_1', 'wheel_neighbors_2', 'section', 'column']].iloc[i:i+lag_count].values)\n",
    "        target.append(df['dozen'].iloc[i+lag_count])\n",
    "    return np.array(lagged_data), np.array(target)\n",
    "\n",
    "lag_count = 10  # Use the last 10 spins as input features\n",
    "X, y = create_lag_features(data, lag_count)\n",
    "\n",
    "# One-hot encode target (dozen)\n",
    "y = to_categorical(y, num_classes=4)  # 4 classes: Dozen 1, Dozen 2, Dozen 3, Green\n",
    "\n",
    "# Step 10: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 11: Build Improved LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(lag_count, 8), return_sequences=True, activation='relu'),  # Updated for 8 features\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(4, activation='softmax')  # 4 output classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 12: Train the Model\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 8)  # Update for 8 features\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 8)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Step 13: Evaluate the Model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Step 14: Save the Model\n",
    "model.save('improved_roulette_lstm_model_with_column.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8afdb7-fc6d-43ee-8f01-98098c8bc594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
